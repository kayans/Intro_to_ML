{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Homework 2: Linear Regression\n",
    "\n",
    "The is the coding potion of Homework 2. The homework is aimed at testing the ability to deal with a real-world dataset and use linear regression on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "Loading the California Housing dataset using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Analyse the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the dataset along with the target variable in a pandas dataframe\n",
    "data = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "# Add target to data\n",
    "data['target'] = housing['target']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1a : Check for missing values in the dataset\n",
    "\n",
    "The dataset might have missing values represented by a `NaN`. Check if the dataset has such missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "676197ad93aa1aa19b1e3898da4c017c",
     "grade": false,
     "grade_id": "p1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "def is_null(dataframe):\n",
    "    \"\"\"\n",
    "    This function takes as input a pandas dataframe and outputs whether the\n",
    "    dataframe has missing values. Missing values can be detected by checking\n",
    "    for the presence of None or NaN. inf or -inf must also be treated as a missing value.\n",
    "\n",
    "    Input:\n",
    "        dataframe: Pandas dataframe\n",
    "    Output:\n",
    "        Return True is there are missing value in the dataframe. If not, return False.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b933622008a9e4a077e1b2a8c239554e",
     "grade": true,
     "grade_id": "p1a-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === DO NOT MOVE/DELETE ===\n",
    "# This cell is used as a placeholder for autograder script injection.\n",
    "\n",
    "# This dataset has no null values; you can run this cell as a sanity check.\n",
    "print(f\"The data has{'' if is_null(data) else ' no'} missing values.\")\n",
    "assert not is_null(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 1b: Studying the distribution of the target variable\n",
    "\n",
    "Plot the histogram of the target variable over a fixed number of bins (say, 30).\n",
    "\n",
    "Example histogram output:\n",
    "\n",
    "![Target histogram](https://jeffcui.com/misc/target_histogram.png)\n",
    "\n",
    "Hint: Use the histogram plotting function available in Seaborn in Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8d012221610349c7d2434b577a4ce32",
     "grade": true,
     "grade_id": "p1b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot histogram of target variable\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1c: Plotting the correlation matrix\n",
    "Given the dataset stored in the `data` variable, plot the correlation matrix for the dataset. The dataset has 9 variables (8 features and one target variable) and thus, the correlation matrix must have a size of `9x9`.\n",
    "\n",
    "Hint: You may use the correlation matrix computation of a dataset provided by the `pandas` library.\n",
    "\n",
    "Link: [What is a correlation matrix?](https://www.displayr.com/what-is-a-correlation-matrix/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b083172c548f71f3f9515e487a868fa1",
     "grade": false,
     "grade_id": "p1c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "def get_correlation_matrix(dataframe):\n",
    "    \"\"\"\n",
    "    Given a pandas dataframe, obtain the correlation matrix\n",
    "    computing the correlation between the entities in the dataset.\n",
    "\n",
    "    Input:\n",
    "        dataframe: Pandas dataframe\n",
    "    Output:\n",
    "        Return the correlation matrix as a pandas dataframe, rounded off to 2 decimal places.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "correlation_matrix = get_correlation_matrix(data)\n",
    "# annot = True to print the values inside the square\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "deeb1bce3582f0d0f8ac169145d4838f",
     "grade": true,
     "grade_id": "p1c-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === DO NOT MOVE/DELETE ===\n",
    "# This cell is used as a placeholder for autograder script injection.\n",
    "\n",
    "# You can check your output against the expected correlation matrix below:\n",
    "ground_truth = np.array([\n",
    "    [1.0, -0.12, 0.33, -0.06, 0.0, 0.02, -0.08, -0.02, 0.69],\n",
    "    [-0.12, 1.0, -0.15, -0.08, -0.3, 0.01, 0.01, -0.11, 0.11],\n",
    "    [0.33, -0.15, 1.0, 0.85, -0.07, 0.0, 0.11, -0.03, 0.15],\n",
    "    [-0.06, -0.08, 0.85, 1.0, -0.07, -0.01, 0.07, 0.01, -0.05],\n",
    "    [0.0, -0.3, -0.07, -0.07, 1.0, 0.07, -0.11, 0.1, -0.02],\n",
    "    [0.02, 0.01, 0.0, -0.01, 0.07, 1.0, 0.0, 0.0, -0.02],\n",
    "    [-0.08, 0.01, 0.11, 0.07, -0.11, 0.0, 1.0, -0.92, -0.14],\n",
    "    [-0.02, -0.11, -0.03, 0.01, 0.1, 0.0, -0.92, 1.0, -0.05],\n",
    "    [0.69, 0.11, 0.15, -0.05, -0.02, -0.02, -0.14, -0.05, 1.0],\n",
    "])\n",
    "assert np.allclose(ground_truth, get_correlation_matrix(data).to_numpy(), rtol=1e-2, atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1d: Extracting relevant variables\n",
    "\n",
    "Based on the correlation matrix obtained in the previous part, identify the top-4 most relevant features from the dataset for predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Manipulation\n",
    "\n",
    "This section is focused on arranging the dataset in a format suitable for training the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2a: Normalize the dataset\n",
    "\n",
    "Find the mean and standard deviation corresponding to each feature and target variable in the dataset. Use the values of the mean and standard deviation to normalize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71860eb9c74a47052a1d855b229b0083",
     "grade": false,
     "grade_id": "p2a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = np.concatenate([data[name].to_numpy()[:, None] for name in housing['feature_names']], axis=1)\n",
    "target = housing['target']\n",
    "\n",
    "# Normalize data\n",
    "def normalize(features, target):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "features_normalized, target_normalized = normalize(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cd6918ed1d597848bbd2c42e3eee9de",
     "grade": true,
     "grade_id": "p2a-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === DO NOT MOVE/DELETE ===\n",
    "# This cell is used as a placeholder for autograder script injection.\n",
    "assert all(np.abs(features_normalized.mean(axis=0)) < 1e-2), \"Mean should be close to 0\"\n",
    "assert all(np.abs(features_normalized.std(axis=0) - 1) < 1e-2), \"Standard deviation should be close to 1\"\n",
    "assert np.abs(target_normalized.mean(axis=0)) < 1e-2, \"Mean should be close to 0\"\n",
    "assert np.abs(target_normalized.std(axis=0) - 1) < 1e-2, \"Standard deviation should be close to 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b: Train-Test Split\n",
    "\n",
    "Use the train-test split function from `sklearn` and execute a 80-20 train-test split of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e24ac49c957cd3d0a2b12fe65992c0da",
     "grade": false,
     "grade_id": "p2b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6205e4ce42238093a9f51eca8c65f5a7",
     "grade": true,
     "grade_id": "p2b-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === DO NOT MOVE/DELETE ===\n",
    "# This cell is used as a placeholder for autograder script injection.\n",
    "\n",
    "# Sanity checking:\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Linear Regression\n",
    "\n",
    "In this part, a linear regression model is used to fit the dataset loaded and normalized above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3a: Code for Linear Regression\n",
    "Implement a closed-form solution for ordinary least squares linear regression in `MyLinearRegression`, and print out the RMSE and $R^2$ between the ground truth and the model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "874d0e119337f0c28ef1696777ff83f9",
     "grade": true,
     "grade_id": "p3a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        # Given X and Y, compute theta using the closed-form solution for linear regression.\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Predict Y for a given X\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on (X_train, Y_train) using Linear Regression \n",
    "my_model = MyLinearRegression()\n",
    "my_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Compute train RMSE using (X_train, Y_train)\n",
    "y_train_predict = my_model.predict(X_train)\n",
    "train_rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "train_r2 = r2_score(Y_train, y_train_predict)\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(train_rmse))\n",
    "print('R2 score is {}'.format(train_r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Compute test RMSE using (X_test, Y_test)\n",
    "y_test_predict = my_model.predict(X_test)\n",
    "test_rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "test_r2 = r2_score(Y_test, y_test_predict)\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(test_rmse))\n",
    "print('R2 score is {}'.format(test_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3b: Compare with LinearRegression from sklearn.linear_model\n",
    "\n",
    "Use LinearRegression from the `sklearn` package to fit the dataset and compare the results obtained with your own implementaion of Linear Regression.\n",
    "\n",
    "The linear regressor should be named `model` for the cells below to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2625c21f986f722c490d8fd6a3299db8",
     "grade": true,
     "grade_id": "p3b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation for training set\n",
    "y_train_predict = model.predict(X_train)\n",
    "sklearn_train_rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "sklearn_train_r2 = r2_score(Y_train, y_train_predict)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(sklearn_train_rmse))\n",
    "print('R2 score is {}'.format(sklearn_train_r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "y_test_predict = model.predict(X_test)\n",
    "sklearn_test_rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "sklearn_test_r2 = r2_score(Y_test, y_test_predict)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(sklearn_test_rmse))\n",
    "print('R2 score is {}'.format(sklearn_test_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3c: Analysis Linear Regression Performance\n",
    "\n",
    "In this section, provide the observed difference in performance along with an explanation of the following:\n",
    "- Difference between training between unnormalized and normalized data.\n",
    "- Difference between training on all features versus training on the top-5 most relevant features in the dataset.\n",
    "- Difference between (1) training on all features (unnormalized), (2) training on top-4 unnormalized features, and (3) training on top-4 normalized features.\n",
    "\n",
    "Write your answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a371e76ca5caa75cbda4e6ea5cfb8c21",
     "grade": true,
     "grade_id": "p3c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc6f77fc95e5420108aa348103e4498d1d0de016cf7e1fd7da540445454c305d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
